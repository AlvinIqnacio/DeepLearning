{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # OpenCV\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "path = \"D:\\FULL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15923 images belonging to 7 classes.\n",
      "Found 3976 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "                                   horizontal_flip=True,\n",
    "                                   validation_split=0.5)\n",
    "training_set = train_datagen.flow_from_directory(path+\"/train\",\n",
    "                                                batch_size=64,\n",
    "                                                target_size=(224,224),\n",
    "                                                shuffle=True,\n",
    "                                                class_mode='categorical',\n",
    "                                                subset='training')\n",
    "\n",
    "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "                                   horizontal_flip=True)\n",
    "validation_set = train_datagen.flow_from_directory(path+\"/test\",\n",
    "                                                batch_size=64,\n",
    "                                                target_size=(224,224),\n",
    "                                                shuffle=True,\n",
    "\n",
    "                                                class_mode='categorical',\n",
    "                                                subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n"
     ]
    }
   ],
   "source": [
    "resnetv2 = keras.applications.ResNet50V2(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n",
    "# KALO FULL DIGANTI FALSE \n",
    "resnetv2.trainable = True\n",
    "print(len(resnetv2.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for layer in resnetv2.layers:\n",
    "  if i > 170:\n",
    "    layer.trainable = False\n",
    "  i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"resnetv2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"resnetv2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">25,613,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,007</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)           │    \u001b[38;5;34m25,613,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │         \u001b[38;5;34m7,007\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,620,807</span> (97.74 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,620,807\u001b[0m (97.74 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,646,687</span> (59.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,646,687\u001b[0m (59.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,974,120</span> (38.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,974,120\u001b[0m (38.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Data Augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomRotation(0.2),  # Rotate up to 20 degrees\n",
    "    tf.keras.layers.RandomTranslation(0.1, 0.15),  # Translate 10% width, 15% height\n",
    "    tf.keras.layers.RandomBrightness(factor=[0.2, 1.0]),  # Change brightness between 0.2 and 1\n",
    "    tf.keras.layers.RandomZoom(height_factor=(-0.1, 0.2), width_factor=(-0.1, 0.2)),  # Zoom out up to 10%, zoom in up to 20%\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),  # Flip horizontally\n",
    "])\n",
    "\n",
    "input = tf.keras.layers.Input(shape=(224, 224, 3))\n",
    "# Apply data augmentation to the input\n",
    "x = data_augmentation(input)\n",
    "x = resnetv2(input, training=False)\n",
    "# x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(7, activation = 'softmax')(x)\n",
    "resnetv2 = tf.keras.models.Model(inputs = input, outputs = x, name = \"resnetv2\")\n",
    "\n",
    "resnetv2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry': 0,\n",
       " 'disgust': 1,\n",
       " 'fear': 2,\n",
       " 'happy': 3,\n",
       " 'neutral': 4,\n",
       " 'sad': 5,\n",
       " 'suprise': 6}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1143s\u001b[0m 18s/step - accuracy: 0.1836 - loss: 1.9342 - val_accuracy: 0.1719 - val_loss: 1.9181\n",
      "Epoch 2/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1051s\u001b[0m 17s/step - accuracy: 0.1911 - loss: 1.9123 - val_accuracy: 0.2344 - val_loss: 1.8996\n",
      "Epoch 3/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1054s\u001b[0m 17s/step - accuracy: 0.2540 - loss: 1.8935 - val_accuracy: 0.2260 - val_loss: 1.8886\n",
      "Epoch 4/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1089s\u001b[0m 18s/step - accuracy: 0.2435 - loss: 1.8818 - val_accuracy: 0.2229 - val_loss: 1.8867\n",
      "Epoch 5/10\n",
      "\u001b[1m 1/62\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18:10\u001b[0m 18s/step - accuracy: 0.1875 - loss: 1.8758"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 168ms/step - accuracy: 0.1875 - loss: 1.8758 - val_accuracy: 0.2721 - val_loss: 1.8481\n",
      "Epoch 6/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1082s\u001b[0m 17s/step - accuracy: 0.2313 - loss: 1.8766 - val_accuracy: 0.2031 - val_loss: 1.8782\n",
      "Epoch 7/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1056s\u001b[0m 17s/step - accuracy: 0.2337 - loss: 1.8730 - val_accuracy: 0.2240 - val_loss: 1.8743\n",
      "Epoch 8/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1054s\u001b[0m 17s/step - accuracy: 0.2354 - loss: 1.8635 - val_accuracy: 0.2458 - val_loss: 1.8676\n",
      "Epoch 9/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1056s\u001b[0m 17s/step - accuracy: 0.2464 - loss: 1.8538 - val_accuracy: 0.2427 - val_loss: 1.8636\n",
      "Epoch 10/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 155ms/step - accuracy: 0.2656 - loss: 1.8408 - val_accuracy: 0.1985 - val_loss: 1.8657\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_set.n // 256\n",
    "validation_steps = validation_set.n // 256\n",
    "\n",
    "resnetv2.compile(optimizer = 'adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "batch_size = 40\n",
    "history = resnetv2.fit(x=training_set,\n",
    "                    validation_data=validation_set,\n",
    "                    epochs=10,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1145s\u001b[0m 17s/step - accuracy: 0.2369 - loss: 1.8525 - val_accuracy: 0.2313 - val_loss: 1.8609\n",
      "Epoch 2/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1078s\u001b[0m 17s/step - accuracy: 0.2407 - loss: 1.8526 - val_accuracy: 0.2323 - val_loss: 1.8584\n",
      "Epoch 3/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1031s\u001b[0m 17s/step - accuracy: 0.2295 - loss: 1.8478 - val_accuracy: 0.2292 - val_loss: 1.8554\n",
      "Epoch 4/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1027s\u001b[0m 17s/step - accuracy: 0.2578 - loss: 1.8379 - val_accuracy: 0.2583 - val_loss: 1.8379\n",
      "Epoch 5/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 151ms/step - accuracy: 0.2031 - loss: 1.8449 - val_accuracy: 0.2574 - val_loss: 1.8449\n",
      "Epoch 6/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1113s\u001b[0m 18s/step - accuracy: 0.2478 - loss: 1.8521 - val_accuracy: 0.2396 - val_loss: 1.8462\n",
      "Epoch 7/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1043s\u001b[0m 17s/step - accuracy: 0.2401 - loss: 1.8532 - val_accuracy: 0.2500 - val_loss: 1.8375\n",
      "Epoch 8/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1030s\u001b[0m 17s/step - accuracy: 0.2382 - loss: 1.8499 - val_accuracy: 0.2365 - val_loss: 1.8557\n",
      "Epoch 9/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1043s\u001b[0m 17s/step - accuracy: 0.2390 - loss: 1.8414 - val_accuracy: 0.2240 - val_loss: 1.8557\n",
      "Epoch 10/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 150ms/step - accuracy: 0.2031 - loss: 1.8027 - val_accuracy: 0.2059 - val_loss: 1.8469\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_set.n // 256\n",
    "validation_steps = validation_set.n // 256\n",
    "\n",
    "resnetv2.compile(optimizer = 'adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "batch_size = 40\n",
    "history = resnetv2.fit(x=training_set,\n",
    "                    validation_data=validation_set,\n",
    "                    epochs=10,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1135s\u001b[0m 17s/step - accuracy: 0.2361 - loss: 1.8458 - val_accuracy: 0.2469 - val_loss: 1.8362\n",
      "Epoch 2/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1044s\u001b[0m 17s/step - accuracy: 0.2302 - loss: 1.8522 - val_accuracy: 0.2531 - val_loss: 1.8534\n",
      "Epoch 3/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1046s\u001b[0m 17s/step - accuracy: 0.2349 - loss: 1.8494 - val_accuracy: 0.2375 - val_loss: 1.8563\n",
      "Epoch 4/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1033s\u001b[0m 17s/step - accuracy: 0.2357 - loss: 1.8420 - val_accuracy: 0.2583 - val_loss: 1.8172\n",
      "Epoch 5/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 161ms/step - accuracy: 0.2031 - loss: 1.8359 - val_accuracy: 0.1985 - val_loss: 1.8512\n",
      "Epoch 6/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1032s\u001b[0m 17s/step - accuracy: 0.2399 - loss: 1.8455 - val_accuracy: 0.2271 - val_loss: 1.8566\n",
      "Epoch 7/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1055s\u001b[0m 17s/step - accuracy: 0.2414 - loss: 1.8549 - val_accuracy: 0.2479 - val_loss: 1.8459\n",
      "Epoch 8/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1090s\u001b[0m 18s/step - accuracy: 0.2608 - loss: 1.8465 - val_accuracy: 0.2260 - val_loss: 1.8564\n",
      "Epoch 9/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1059s\u001b[0m 17s/step - accuracy: 0.2431 - loss: 1.8446 - val_accuracy: 0.2219 - val_loss: 1.8664\n",
      "Epoch 10/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 145ms/step - accuracy: 0.2188 - loss: 1.8966 - val_accuracy: 0.1838 - val_loss: 1.8854\n",
      "Epoch 11/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1051s\u001b[0m 17s/step - accuracy: 0.2427 - loss: 1.8426 - val_accuracy: 0.2427 - val_loss: 1.8545\n",
      "Epoch 12/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1037s\u001b[0m 17s/step - accuracy: 0.2429 - loss: 1.8462 - val_accuracy: 0.2406 - val_loss: 1.8633\n",
      "Epoch 13/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1027s\u001b[0m 17s/step - accuracy: 0.2432 - loss: 1.8398 - val_accuracy: 0.2219 - val_loss: 1.8334\n",
      "Epoch 14/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1029s\u001b[0m 17s/step - accuracy: 0.2393 - loss: 1.8439 - val_accuracy: 0.2333 - val_loss: 1.8448\n",
      "Epoch 15/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 142ms/step - accuracy: 0.1875 - loss: 1.8526 - val_accuracy: 0.2206 - val_loss: 1.8830\n",
      "Epoch 16/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1013s\u001b[0m 16s/step - accuracy: 0.2360 - loss: 1.8422 - val_accuracy: 0.2479 - val_loss: 1.8501\n",
      "Epoch 17/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1059s\u001b[0m 17s/step - accuracy: 0.2495 - loss: 1.8558 - val_accuracy: 0.2490 - val_loss: 1.8442\n",
      "Epoch 18/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1058s\u001b[0m 17s/step - accuracy: 0.2486 - loss: 1.8420 - val_accuracy: 0.2458 - val_loss: 1.8402\n",
      "Epoch 19/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1058s\u001b[0m 17s/step - accuracy: 0.2416 - loss: 1.8491 - val_accuracy: 0.2198 - val_loss: 1.8444\n",
      "Epoch 20/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 178ms/step - accuracy: 0.1719 - loss: 1.8358 - val_accuracy: 0.2206 - val_loss: 1.8518\n",
      "Epoch 21/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1087s\u001b[0m 17s/step - accuracy: 0.2291 - loss: 1.8534 - val_accuracy: 0.2604 - val_loss: 1.8244\n",
      "Epoch 22/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1060s\u001b[0m 17s/step - accuracy: 0.2440 - loss: 1.8472 - val_accuracy: 0.2135 - val_loss: 1.8652\n",
      "Epoch 23/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1050s\u001b[0m 17s/step - accuracy: 0.2355 - loss: 1.8413 - val_accuracy: 0.2490 - val_loss: 1.8362\n",
      "Epoch 24/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1024s\u001b[0m 16s/step - accuracy: 0.2395 - loss: 1.8441 - val_accuracy: 0.2698 - val_loss: 1.8288\n",
      "Epoch 25/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 166ms/step - accuracy: 0.2031 - loss: 1.9163 - val_accuracy: 0.2721 - val_loss: 1.8353\n",
      "Epoch 26/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1049s\u001b[0m 17s/step - accuracy: 0.2432 - loss: 1.8458 - val_accuracy: 0.2469 - val_loss: 1.8504\n",
      "Epoch 27/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1047s\u001b[0m 17s/step - accuracy: 0.2531 - loss: 1.8300 - val_accuracy: 0.2250 - val_loss: 1.8637\n",
      "Epoch 28/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1070s\u001b[0m 17s/step - accuracy: 0.2397 - loss: 1.8479 - val_accuracy: 0.2438 - val_loss: 1.8357\n",
      "Epoch 29/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1056s\u001b[0m 17s/step - accuracy: 0.2435 - loss: 1.8381 - val_accuracy: 0.2313 - val_loss: 1.8524\n",
      "Epoch 30/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 147ms/step - accuracy: 0.1250 - loss: 1.9067 - val_accuracy: 0.2132 - val_loss: 1.8493\n",
      "Epoch 31/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1056s\u001b[0m 17s/step - accuracy: 0.2403 - loss: 1.8425 - val_accuracy: 0.2260 - val_loss: 1.8472\n",
      "Epoch 32/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1038s\u001b[0m 17s/step - accuracy: 0.2410 - loss: 1.8401 - val_accuracy: 0.2458 - val_loss: 1.8611\n",
      "Epoch 33/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1023s\u001b[0m 17s/step - accuracy: 0.2484 - loss: 1.8331 - val_accuracy: 0.2292 - val_loss: 1.8600\n",
      "Epoch 34/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1040s\u001b[0m 17s/step - accuracy: 0.2520 - loss: 1.8324 - val_accuracy: 0.2510 - val_loss: 1.8389\n",
      "Epoch 35/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 137ms/step - accuracy: 0.2812 - loss: 1.7939 - val_accuracy: 0.2574 - val_loss: 1.8376\n",
      "Epoch 36/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1028s\u001b[0m 17s/step - accuracy: 0.2505 - loss: 1.8327 - val_accuracy: 0.2562 - val_loss: 1.8155\n",
      "Epoch 37/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1098s\u001b[0m 18s/step - accuracy: 0.2438 - loss: 1.8493 - val_accuracy: 0.2490 - val_loss: 1.8361\n",
      "Epoch 38/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1445s\u001b[0m 23s/step - accuracy: 0.2544 - loss: 1.8370 - val_accuracy: 0.2302 - val_loss: 1.8507\n",
      "Epoch 39/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1475s\u001b[0m 24s/step - accuracy: 0.2329 - loss: 1.8538 - val_accuracy: 0.2500 - val_loss: 1.8517\n",
      "Epoch 40/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 205ms/step - accuracy: 0.2500 - loss: 1.7806 - val_accuracy: 0.2868 - val_loss: 1.8181\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_set.n // 256\n",
    "validation_steps = validation_set.n // 256\n",
    "\n",
    "resnetv2.compile(optimizer = 'adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "batch_size = 40\n",
    "history = resnetv2.fit(x=training_set,\n",
    "                    validation_data=validation_set,\n",
    "                    epochs=40,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnetv2.save(\"resnetv2-lbh-1.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1159s\u001b[0m 18s/step - accuracy: 0.2329 - loss: 1.8496\n",
      "Epoch 2/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1098s\u001b[0m 18s/step - accuracy: 0.2475 - loss: 1.8366\n",
      "Epoch 3/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1094s\u001b[0m 18s/step - accuracy: 0.2461 - loss: 1.8410\n",
      "Epoch 4/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1100s\u001b[0m 18s/step - accuracy: 0.2448 - loss: 1.8367\n",
      "Epoch 5/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - accuracy: 0.2031 - loss: 1.8613 \n",
      "Epoch 6/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1113s\u001b[0m 18s/step - accuracy: 0.2428 - loss: 1.8414\n",
      "Epoch 7/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1108s\u001b[0m 18s/step - accuracy: 0.2326 - loss: 1.8483\n",
      "Epoch 8/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1088s\u001b[0m 18s/step - accuracy: 0.2434 - loss: 1.8515\n",
      "Epoch 9/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1083s\u001b[0m 17s/step - accuracy: 0.2500 - loss: 1.8313\n",
      "Epoch 10/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.2344 - loss: 1.8254 \n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_set.n // 256\n",
    "validation_steps = validation_set.n // 256\n",
    "\n",
    "resnetv2.compile(optimizer = 'adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "batch_size = 40\n",
    "history = resnetv2.fit(x=training_set,\n",
    "                    epochs=10,\n",
    "                    steps_per_epoch=steps_per_epoch\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1383s\u001b[0m 21s/step - accuracy: 0.2458 - loss: 1.8280 - val_accuracy: 0.2313 - val_loss: 1.8544\n",
      "Epoch 2/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1407s\u001b[0m 23s/step - accuracy: 0.2351 - loss: 1.8413 - val_accuracy: 0.2313 - val_loss: 1.8405\n",
      "Epoch 3/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1261s\u001b[0m 20s/step - accuracy: 0.2361 - loss: 1.8475 - val_accuracy: 0.2385 - val_loss: 1.8461\n",
      "Epoch 4/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1199s\u001b[0m 19s/step - accuracy: 0.2239 - loss: 1.8428 - val_accuracy: 0.2438 - val_loss: 1.8294\n",
      "Epoch 5/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 147ms/step - accuracy: 0.2656 - loss: 1.8201 - val_accuracy: 0.2868 - val_loss: 1.7992\n",
      "Epoch 6/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1189s\u001b[0m 19s/step - accuracy: 0.2444 - loss: 1.8391 - val_accuracy: 0.2208 - val_loss: 1.8617\n",
      "Epoch 7/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1161s\u001b[0m 19s/step - accuracy: 0.2313 - loss: 1.8408 - val_accuracy: 0.2469 - val_loss: 1.8491\n",
      "Epoch 8/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1180s\u001b[0m 19s/step - accuracy: 0.2348 - loss: 1.8513 - val_accuracy: 0.2333 - val_loss: 1.8508\n",
      "Epoch 9/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1173s\u001b[0m 19s/step - accuracy: 0.2272 - loss: 1.8449 - val_accuracy: 0.2281 - val_loss: 1.8633\n",
      "Epoch 10/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 145ms/step - accuracy: 0.2188 - loss: 1.9069 - val_accuracy: 0.2353 - val_loss: 1.8416\n",
      "Epoch 11/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1157s\u001b[0m 19s/step - accuracy: 0.2531 - loss: 1.8442 - val_accuracy: 0.2469 - val_loss: 1.8357\n",
      "Epoch 12/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1177s\u001b[0m 19s/step - accuracy: 0.2307 - loss: 1.8511 - val_accuracy: 0.2510 - val_loss: 1.8368\n",
      "Epoch 13/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1178s\u001b[0m 19s/step - accuracy: 0.2375 - loss: 1.8470 - val_accuracy: 0.2604 - val_loss: 1.8488\n",
      "Epoch 14/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1165s\u001b[0m 19s/step - accuracy: 0.2400 - loss: 1.8548 - val_accuracy: 0.2604 - val_loss: 1.8239\n",
      "Epoch 15/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 188ms/step - accuracy: 0.3594 - loss: 1.7468 - val_accuracy: 0.2941 - val_loss: 1.8274\n",
      "Epoch 16/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1200s\u001b[0m 19s/step - accuracy: 0.2362 - loss: 1.8543 - val_accuracy: 0.2375 - val_loss: 1.8415\n",
      "Epoch 17/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1175s\u001b[0m 19s/step - accuracy: 0.2630 - loss: 1.8261 - val_accuracy: 0.2521 - val_loss: 1.8290\n",
      "Epoch 18/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1200s\u001b[0m 19s/step - accuracy: 0.2272 - loss: 1.8406 - val_accuracy: 0.2427 - val_loss: 1.8380\n",
      "Epoch 19/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1177s\u001b[0m 19s/step - accuracy: 0.2395 - loss: 1.8505 - val_accuracy: 0.2323 - val_loss: 1.8654\n",
      "Epoch 20/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 157ms/step - accuracy: 0.2812 - loss: 1.7935 - val_accuracy: 0.2574 - val_loss: 1.8724\n",
      "Epoch 21/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1168s\u001b[0m 19s/step - accuracy: 0.2384 - loss: 1.8436 - val_accuracy: 0.2417 - val_loss: 1.8331\n",
      "Epoch 22/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1167s\u001b[0m 19s/step - accuracy: 0.2542 - loss: 1.8427 - val_accuracy: 0.2438 - val_loss: 1.8502\n",
      "Epoch 23/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1169s\u001b[0m 19s/step - accuracy: 0.2440 - loss: 1.8494 - val_accuracy: 0.2396 - val_loss: 1.8424\n",
      "Epoch 24/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1169s\u001b[0m 19s/step - accuracy: 0.2364 - loss: 1.8406 - val_accuracy: 0.2500 - val_loss: 1.8393\n",
      "Epoch 25/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 153ms/step - accuracy: 0.2188 - loss: 1.8426 - val_accuracy: 0.2059 - val_loss: 1.8332\n",
      "Epoch 26/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1167s\u001b[0m 19s/step - accuracy: 0.2317 - loss: 1.8517 - val_accuracy: 0.2292 - val_loss: 1.8543\n",
      "Epoch 27/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1173s\u001b[0m 19s/step - accuracy: 0.2460 - loss: 1.8437 - val_accuracy: 0.2323 - val_loss: 1.8551\n",
      "Epoch 28/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1170s\u001b[0m 19s/step - accuracy: 0.2330 - loss: 1.8530 - val_accuracy: 0.2469 - val_loss: 1.8288\n",
      "Epoch 29/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1170s\u001b[0m 19s/step - accuracy: 0.2414 - loss: 1.8435 - val_accuracy: 0.2323 - val_loss: 1.8474\n",
      "Epoch 30/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 148ms/step - accuracy: 0.2656 - loss: 1.7530 - val_accuracy: 0.2500 - val_loss: 1.8707\n",
      "Epoch 31/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1167s\u001b[0m 19s/step - accuracy: 0.2461 - loss: 1.8377 - val_accuracy: 0.2156 - val_loss: 1.8457\n",
      "Epoch 32/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1152s\u001b[0m 19s/step - accuracy: 0.2524 - loss: 1.8458 - val_accuracy: 0.2333 - val_loss: 1.8497\n",
      "Epoch 33/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1164s\u001b[0m 19s/step - accuracy: 0.2464 - loss: 1.8398 - val_accuracy: 0.2323 - val_loss: 1.8546\n",
      "Epoch 34/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1158s\u001b[0m 19s/step - accuracy: 0.2564 - loss: 1.8245 - val_accuracy: 0.2458 - val_loss: 1.8366\n",
      "Epoch 35/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 141ms/step - accuracy: 0.3125 - loss: 1.7838 - val_accuracy: 0.2500 - val_loss: 1.8214\n",
      "Epoch 36/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1174s\u001b[0m 19s/step - accuracy: 0.2543 - loss: 1.8324 - val_accuracy: 0.2333 - val_loss: 1.8506\n",
      "Epoch 37/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1122s\u001b[0m 18s/step - accuracy: 0.2462 - loss: 1.8281 - val_accuracy: 0.2438 - val_loss: 1.8312\n",
      "Epoch 38/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1127s\u001b[0m 18s/step - accuracy: 0.2498 - loss: 1.8319 - val_accuracy: 0.2521 - val_loss: 1.8443\n",
      "Epoch 39/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1121s\u001b[0m 18s/step - accuracy: 0.2476 - loss: 1.8398 - val_accuracy: 0.2385 - val_loss: 1.8466\n",
      "Epoch 40/40\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 146ms/step - accuracy: 0.2031 - loss: 1.9094 - val_accuracy: 0.2353 - val_loss: 1.8365\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_set.n // 256\n",
    "validation_steps = validation_set.n // 256\n",
    "\n",
    "resnetv2.compile(optimizer = 'adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "batch_size = 40\n",
    "history = resnetv2.fit(x=training_set,\n",
    "                    validation_data=validation_set,\n",
    "                    epochs=40,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 316 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "new_resnetv2_lbh = tf.keras.models.load_model(\"resnetv2-lbh-110.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m901s\u001b[0m 14s/step - accuracy: 0.2299 - loss: 1.8437 - val_accuracy: 0.2479 - val_loss: 1.8484\n",
      "Epoch 2/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m876s\u001b[0m 14s/step - accuracy: 0.2522 - loss: 1.8425 - val_accuracy: 0.2385 - val_loss: 1.8435\n",
      "Epoch 3/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m867s\u001b[0m 14s/step - accuracy: 0.2377 - loss: 1.8507 - val_accuracy: 0.2333 - val_loss: 1.8637\n",
      "Epoch 4/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m863s\u001b[0m 14s/step - accuracy: 0.2557 - loss: 1.8398 - val_accuracy: 0.2396 - val_loss: 1.8358\n",
      "Epoch 5/30\n",
      "\u001b[1m 1/62\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15:12\u001b[0m 15s/step - accuracy: 0.2188 - loss: 1.8736"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 133ms/step - accuracy: 0.2188 - loss: 1.8736 - val_accuracy: 0.2794 - val_loss: 1.8531\n",
      "Epoch 6/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m867s\u001b[0m 14s/step - accuracy: 0.2444 - loss: 1.8461 - val_accuracy: 0.2469 - val_loss: 1.8457\n",
      "Epoch 7/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m861s\u001b[0m 14s/step - accuracy: 0.2522 - loss: 1.8347 - val_accuracy: 0.2479 - val_loss: 1.8358\n",
      "Epoch 8/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m866s\u001b[0m 14s/step - accuracy: 0.2389 - loss: 1.8568 - val_accuracy: 0.2417 - val_loss: 1.8475\n",
      "Epoch 9/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m865s\u001b[0m 14s/step - accuracy: 0.2324 - loss: 1.8560 - val_accuracy: 0.2646 - val_loss: 1.8421\n",
      "Epoch 10/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 111ms/step - accuracy: 0.3438 - loss: 1.7340 - val_accuracy: 0.2574 - val_loss: 1.8645\n",
      "Epoch 11/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m861s\u001b[0m 14s/step - accuracy: 0.2321 - loss: 1.8508 - val_accuracy: 0.2177 - val_loss: 1.8670\n",
      "Epoch 12/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m871s\u001b[0m 14s/step - accuracy: 0.2318 - loss: 1.8469 - val_accuracy: 0.2781 - val_loss: 1.8182\n",
      "Epoch 13/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m860s\u001b[0m 14s/step - accuracy: 0.2494 - loss: 1.8383 - val_accuracy: 0.2292 - val_loss: 1.8548\n",
      "Epoch 14/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m865s\u001b[0m 14s/step - accuracy: 0.2451 - loss: 1.8400 - val_accuracy: 0.2427 - val_loss: 1.8460\n",
      "Epoch 15/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 106ms/step - accuracy: 0.2745 - loss: 1.8300 - val_accuracy: 0.2794 - val_loss: 1.8098\n",
      "Epoch 16/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m862s\u001b[0m 14s/step - accuracy: 0.2368 - loss: 1.8456 - val_accuracy: 0.2510 - val_loss: 1.8471\n",
      "Epoch 17/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m860s\u001b[0m 14s/step - accuracy: 0.2379 - loss: 1.8294 - val_accuracy: 0.2510 - val_loss: 1.8344\n",
      "Epoch 18/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m871s\u001b[0m 14s/step - accuracy: 0.2349 - loss: 1.8560 - val_accuracy: 0.2302 - val_loss: 1.8484\n",
      "Epoch 19/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m867s\u001b[0m 14s/step - accuracy: 0.2310 - loss: 1.8600 - val_accuracy: 0.2469 - val_loss: 1.8439\n",
      "Epoch 20/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 118ms/step - accuracy: 0.2812 - loss: 1.8250 - val_accuracy: 0.2353 - val_loss: 1.9030\n",
      "Epoch 21/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m867s\u001b[0m 14s/step - accuracy: 0.2359 - loss: 1.8371 - val_accuracy: 0.2323 - val_loss: 1.8372\n",
      "Epoch 22/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m858s\u001b[0m 14s/step - accuracy: 0.2435 - loss: 1.8368 - val_accuracy: 0.2396 - val_loss: 1.8456\n",
      "Epoch 23/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m859s\u001b[0m 14s/step - accuracy: 0.2378 - loss: 1.8460 - val_accuracy: 0.2313 - val_loss: 1.8554\n",
      "Epoch 24/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m864s\u001b[0m 14s/step - accuracy: 0.2517 - loss: 1.8402 - val_accuracy: 0.2542 - val_loss: 1.8312\n",
      "Epoch 25/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 113ms/step - accuracy: 0.2500 - loss: 1.8196 - val_accuracy: 0.2206 - val_loss: 1.8744\n",
      "Epoch 26/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m861s\u001b[0m 14s/step - accuracy: 0.2619 - loss: 1.8414 - val_accuracy: 0.2458 - val_loss: 1.8516\n",
      "Epoch 27/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m862s\u001b[0m 14s/step - accuracy: 0.2542 - loss: 1.8356 - val_accuracy: 0.2427 - val_loss: 1.8347\n",
      "Epoch 28/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m869s\u001b[0m 14s/step - accuracy: 0.2360 - loss: 1.8520 - val_accuracy: 0.2448 - val_loss: 1.8416\n",
      "Epoch 29/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m883s\u001b[0m 14s/step - accuracy: 0.2558 - loss: 1.8299 - val_accuracy: 0.2479 - val_loss: 1.8432\n",
      "Epoch 30/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 110ms/step - accuracy: 0.2188 - loss: 1.8702 - val_accuracy: 0.3015 - val_loss: 1.8008\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_set.n // 256\n",
    "validation_steps = validation_set.n // 256\n",
    "\n",
    "new_resnetv2_lbh.compile(optimizer = 'adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "batch_size = 40\n",
    "history = new_resnetv2_lbh.fit(x=training_set,\n",
    "                    validation_data=validation_set,\n",
    "                    epochs=30,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_resnetv2_lbh.save(\"resnetv2-lbh-140.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 316 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "new2_resnetv2_lbh = tf.keras.models.load_model(\"resnetv2-lbh-140.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1358s\u001b[0m 21s/step - accuracy: 0.2374 - loss: 1.8396 - val_accuracy: 0.2406 - val_loss: 1.8576\n",
      "Epoch 2/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1359s\u001b[0m 22s/step - accuracy: 0.2166 - loss: 1.8475 - val_accuracy: 0.2198 - val_loss: 1.8665\n",
      "Epoch 3/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1220s\u001b[0m 20s/step - accuracy: 0.2466 - loss: 1.8375 - val_accuracy: 0.2385 - val_loss: 1.8320\n",
      "Epoch 4/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1247s\u001b[0m 20s/step - accuracy: 0.2454 - loss: 1.8508 - val_accuracy: 0.2510 - val_loss: 1.8309\n",
      "Epoch 5/30\n",
      "\u001b[1m 1/62\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21:38\u001b[0m 21s/step - accuracy: 0.2500 - loss: 1.8161"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 171ms/step - accuracy: 0.2500 - loss: 1.8161 - val_accuracy: 0.2426 - val_loss: 1.8513\n",
      "Epoch 6/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1265s\u001b[0m 20s/step - accuracy: 0.2442 - loss: 1.8384 - val_accuracy: 0.2552 - val_loss: 1.8298\n",
      "Epoch 7/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1350s\u001b[0m 22s/step - accuracy: 0.2359 - loss: 1.8463 - val_accuracy: 0.2365 - val_loss: 1.8520\n",
      "Epoch 8/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1401s\u001b[0m 23s/step - accuracy: 0.2307 - loss: 1.8493 - val_accuracy: 0.2375 - val_loss: 1.8462\n",
      "Epoch 9/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1316s\u001b[0m 21s/step - accuracy: 0.2549 - loss: 1.8414 - val_accuracy: 0.2448 - val_loss: 1.8424\n",
      "Epoch 10/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 155ms/step - accuracy: 0.2500 - loss: 1.7879 - val_accuracy: 0.2721 - val_loss: 1.8104\n",
      "Epoch 11/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1382s\u001b[0m 22s/step - accuracy: 0.2429 - loss: 1.8441 - val_accuracy: 0.2427 - val_loss: 1.8415\n",
      "Epoch 12/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1285s\u001b[0m 21s/step - accuracy: 0.2430 - loss: 1.8516 - val_accuracy: 0.2396 - val_loss: 1.8375\n",
      "Epoch 13/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1254s\u001b[0m 20s/step - accuracy: 0.2467 - loss: 1.8484 - val_accuracy: 0.2458 - val_loss: 1.8355\n",
      "Epoch 14/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1294s\u001b[0m 21s/step - accuracy: 0.2446 - loss: 1.8491 - val_accuracy: 0.2313 - val_loss: 1.8511\n",
      "Epoch 15/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 148ms/step - accuracy: 0.3594 - loss: 1.7925 - val_accuracy: 0.2206 - val_loss: 1.8199\n",
      "Epoch 16/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1289s\u001b[0m 21s/step - accuracy: 0.2341 - loss: 1.8501 - val_accuracy: 0.2271 - val_loss: 1.8566\n",
      "Epoch 17/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1299s\u001b[0m 21s/step - accuracy: 0.2400 - loss: 1.8393 - val_accuracy: 0.2625 - val_loss: 1.8366\n",
      "Epoch 18/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1317s\u001b[0m 21s/step - accuracy: 0.2492 - loss: 1.8273 - val_accuracy: 0.2302 - val_loss: 1.8368\n",
      "Epoch 19/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1320s\u001b[0m 21s/step - accuracy: 0.2336 - loss: 1.8421 - val_accuracy: 0.2469 - val_loss: 1.8465\n",
      "Epoch 20/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 198ms/step - accuracy: 0.2188 - loss: 1.8454 - val_accuracy: 0.2647 - val_loss: 1.8306\n",
      "Epoch 21/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1294s\u001b[0m 21s/step - accuracy: 0.2355 - loss: 1.8471 - val_accuracy: 0.2458 - val_loss: 1.8409\n",
      "Epoch 22/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1291s\u001b[0m 21s/step - accuracy: 0.2513 - loss: 1.8452 - val_accuracy: 0.2323 - val_loss: 1.8454\n",
      "Epoch 23/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1269s\u001b[0m 20s/step - accuracy: 0.2380 - loss: 1.8382 - val_accuracy: 0.2583 - val_loss: 1.8405\n",
      "Epoch 24/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1290s\u001b[0m 21s/step - accuracy: 0.2600 - loss: 1.8266 - val_accuracy: 0.2271 - val_loss: 1.8509\n",
      "Epoch 25/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 153ms/step - accuracy: 0.2344 - loss: 1.8569 - val_accuracy: 0.2574 - val_loss: 1.8080\n",
      "Epoch 26/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1327s\u001b[0m 21s/step - accuracy: 0.2573 - loss: 1.8454 - val_accuracy: 0.2417 - val_loss: 1.8502\n",
      "Epoch 27/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1306s\u001b[0m 21s/step - accuracy: 0.2434 - loss: 1.8384 - val_accuracy: 0.2458 - val_loss: 1.8474\n",
      "Epoch 28/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1298s\u001b[0m 21s/step - accuracy: 0.2501 - loss: 1.8322 - val_accuracy: 0.2083 - val_loss: 1.8569\n",
      "Epoch 29/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1303s\u001b[0m 21s/step - accuracy: 0.2430 - loss: 1.8495 - val_accuracy: 0.2573 - val_loss: 1.8452\n",
      "Epoch 30/30\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 156ms/step - accuracy: 0.2812 - loss: 1.8096 - val_accuracy: 0.2426 - val_loss: 1.8867\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_set.n // 256\n",
    "validation_steps = validation_set.n // 256\n",
    "\n",
    "new2_resnetv2_lbh.compile(optimizer = 'adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "batch_size = 40\n",
    "history = new2_resnetv2_lbh.fit(x=training_set,\n",
    "                    validation_data=validation_set,\n",
    "                    epochs=30,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new2_resnetv2_lbh.save(\"resnetv2-lbh-170.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
