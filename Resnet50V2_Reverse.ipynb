{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # OpenCV\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "path = \"D:\\FULL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15923 images belonging to 7 classes.\n",
      "Found 3976 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "                                   horizontal_flip=True,\n",
    "                                   validation_split=0.5)\n",
    "training_set = train_datagen.flow_from_directory(path+\"/train\",\n",
    "                                                batch_size=64,\n",
    "                                                target_size=(224,224),\n",
    "                                                shuffle=True,\n",
    "                                                class_mode='categorical',\n",
    "                                                subset='training')\n",
    "\n",
    "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "                                   horizontal_flip=True)\n",
    "validation_set = train_datagen.flow_from_directory(path+\"/test\",\n",
    "                                                batch_size=64,\n",
    "                                                target_size=(224,224),\n",
    "                                                shuffle=True,\n",
    "\n",
    "                                                class_mode='categorical',\n",
    "                                                subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n"
     ]
    }
   ],
   "source": [
    "resnetv2 = keras.applications.ResNet50V2(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n",
    "# KALO FULL DIGANTI FALSE \n",
    "resnetv2.trainable = True\n",
    "print(len(resnetv2.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for layer in resnetv2.layers:\n",
    "  if i < 170:\n",
    "    layer.trainable = False\n",
    "  i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"resnetv2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"resnetv2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">25,613,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,007</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_27 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)           │    \u001b[38;5;34m25,613,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_9 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │         \u001b[38;5;34m7,007\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,620,807</span> (97.74 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,620,807\u001b[0m (97.74 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,935,687</span> (37.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,935,687\u001b[0m (37.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,685,120</span> (59.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m15,685,120\u001b[0m (59.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Data Augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomRotation(0.2),  # Rotate up to 20 degrees\n",
    "    tf.keras.layers.RandomTranslation(0.1, 0.15),  # Translate 10% width, 15% height\n",
    "    tf.keras.layers.RandomBrightness(factor=[0.2, 1.0]),  # Change brightness between 0.2 and 1\n",
    "    tf.keras.layers.RandomZoom(height_factor=(-0.1, 0.2), width_factor=(-0.1, 0.2)),  # Zoom out up to 10%, zoom in up to 20%\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),  # Flip horizontally\n",
    "])\n",
    "\n",
    "input = tf.keras.layers.Input(shape=(224, 224, 3))\n",
    "# Apply data augmentation to the input\n",
    "x = data_augmentation(input)\n",
    "x = resnetv2(input, training=False)\n",
    "# x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(7, activation = 'softmax')(x)\n",
    "resnetv2 = tf.keras.models.Model(inputs = input, outputs = x, name = \"resnetv2\")\n",
    "\n",
    "resnetv2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 5s/step - accuracy: 0.2710 - loss: 1.9238 - val_accuracy: 0.2740 - val_loss: 1.8953\n",
      "Epoch 2/5\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 5s/step - accuracy: 0.3643 - loss: 1.8615 - val_accuracy: 0.2531 - val_loss: 1.8831\n",
      "Epoch 3/5\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 6s/step - accuracy: 0.4185 - loss: 1.8122 - val_accuracy: 0.2740 - val_loss: 1.8499\n",
      "Epoch 4/5\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 5s/step - accuracy: 0.4192 - loss: 1.7745 - val_accuracy: 0.2958 - val_loss: 1.8357\n",
      "Epoch 5/5\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 129ms/step - accuracy: 0.3906 - loss: 1.7811 - val_accuracy: 0.3382 - val_loss: 1.7969\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_set.n // 256\n",
    "validation_steps = validation_set.n // 256\n",
    "\n",
    "resnetv2.compile(optimizer = 'adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "batch_size = 40\n",
    "history = resnetv2.fit(x=training_set,\n",
    "                    validation_data=validation_set,\n",
    "                    epochs=5,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 5s/step - accuracy: 0.4371 - loss: 1.7337 - val_accuracy: 0.2583 - val_loss: 1.8324\n",
      "Epoch 2/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 5s/step - accuracy: 0.4210 - loss: 1.7157 - val_accuracy: 0.4083 - val_loss: 1.7102\n",
      "Epoch 3/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 5s/step - accuracy: 0.4360 - loss: 1.6900 - val_accuracy: 0.4521 - val_loss: 1.6749\n",
      "Epoch 4/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 5s/step - accuracy: 0.4460 - loss: 1.6619 - val_accuracy: 0.4146 - val_loss: 1.6844\n",
      "Epoch 5/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - accuracy: 0.3906 - loss: 1.7348 - val_accuracy: 0.4485 - val_loss: 1.6301\n",
      "Epoch 6/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 5s/step - accuracy: 0.4609 - loss: 1.6301 - val_accuracy: 0.4510 - val_loss: 1.6419\n",
      "Epoch 7/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 5s/step - accuracy: 0.4485 - loss: 1.6211 - val_accuracy: 0.4427 - val_loss: 1.6371\n",
      "Epoch 8/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 5s/step - accuracy: 0.4636 - loss: 1.5960 - val_accuracy: 0.4469 - val_loss: 1.6291\n",
      "Epoch 9/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 5s/step - accuracy: 0.4577 - loss: 1.5803 - val_accuracy: 0.4469 - val_loss: 1.5935\n",
      "Epoch 10/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - accuracy: 0.4219 - loss: 1.6144 - val_accuracy: 0.4412 - val_loss: 1.6271\n",
      "Epoch 11/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 5s/step - accuracy: 0.4442 - loss: 1.5864 - val_accuracy: 0.4656 - val_loss: 1.5787\n",
      "Epoch 12/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 5s/step - accuracy: 0.4611 - loss: 1.5535 - val_accuracy: 0.4521 - val_loss: 1.5927\n",
      "Epoch 13/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 5s/step - accuracy: 0.4915 - loss: 1.5159 - val_accuracy: 0.4219 - val_loss: 1.6462\n",
      "Epoch 14/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 5s/step - accuracy: 0.4799 - loss: 1.5091 - val_accuracy: 0.4615 - val_loss: 1.5432\n",
      "Epoch 15/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 121ms/step - accuracy: 0.5000 - loss: 1.5349 - val_accuracy: 0.4706 - val_loss: 1.5264\n",
      "Epoch 16/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 5s/step - accuracy: 0.4819 - loss: 1.4841 - val_accuracy: 0.4490 - val_loss: 1.5530\n",
      "Epoch 17/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 5s/step - accuracy: 0.4776 - loss: 1.4823 - val_accuracy: 0.4885 - val_loss: 1.4798\n",
      "Epoch 18/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 5s/step - accuracy: 0.4823 - loss: 1.4701 - val_accuracy: 0.4656 - val_loss: 1.5044\n",
      "Epoch 19/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 5s/step - accuracy: 0.4799 - loss: 1.4677 - val_accuracy: 0.4656 - val_loss: 1.5047\n",
      "Epoch 20/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 116ms/step - accuracy: 0.5469 - loss: 1.3896 - val_accuracy: 0.4779 - val_loss: 1.4635\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_set.n // 256\n",
    "validation_steps = validation_set.n // 256\n",
    "\n",
    "resnetv2.compile(optimizer = 'adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "batch_size = 40\n",
    "history = resnetv2.fit(x=training_set,\n",
    "                    validation_data=validation_set,\n",
    "                    epochs=20,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 5s/step - accuracy: 0.4962 - loss: 1.4484 - val_accuracy: 0.4531 - val_loss: 1.4892\n",
      "Epoch 2/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 5s/step - accuracy: 0.4944 - loss: 1.4398 - val_accuracy: 0.4938 - val_loss: 1.4579\n",
      "Epoch 3/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 5s/step - accuracy: 0.5062 - loss: 1.3956 - val_accuracy: 0.4552 - val_loss: 1.5042\n",
      "Epoch 4/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 5s/step - accuracy: 0.4908 - loss: 1.4122 - val_accuracy: 0.4740 - val_loss: 1.4728\n",
      "Epoch 5/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - accuracy: 0.6094 - loss: 1.3634 - val_accuracy: 0.5147 - val_loss: 1.4054\n",
      "Epoch 6/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 5s/step - accuracy: 0.5117 - loss: 1.3768 - val_accuracy: 0.4917 - val_loss: 1.4265\n",
      "Epoch 7/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 5s/step - accuracy: 0.4981 - loss: 1.3968 - val_accuracy: 0.5240 - val_loss: 1.3583\n",
      "Epoch 8/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 5s/step - accuracy: 0.5322 - loss: 1.3122 - val_accuracy: 0.4833 - val_loss: 1.4134\n",
      "Epoch 9/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 5s/step - accuracy: 0.5443 - loss: 1.3030 - val_accuracy: 0.4802 - val_loss: 1.4535\n",
      "Epoch 10/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 116ms/step - accuracy: 0.5312 - loss: 1.3119 - val_accuracy: 0.4485 - val_loss: 1.4834\n",
      "Epoch 11/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 5s/step - accuracy: 0.5119 - loss: 1.3441 - val_accuracy: 0.5000 - val_loss: 1.4017\n",
      "Epoch 12/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 5s/step - accuracy: 0.5408 - loss: 1.2984 - val_accuracy: 0.5156 - val_loss: 1.3730\n",
      "Epoch 13/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 5s/step - accuracy: 0.5506 - loss: 1.2782 - val_accuracy: 0.4958 - val_loss: 1.3859\n",
      "Epoch 14/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 5s/step - accuracy: 0.5202 - loss: 1.3179 - val_accuracy: 0.4896 - val_loss: 1.4166\n",
      "Epoch 15/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 116ms/step - accuracy: 0.5000 - loss: 1.3771 - val_accuracy: 0.4853 - val_loss: 1.3685\n",
      "Epoch 16/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 5s/step - accuracy: 0.5346 - loss: 1.3126 - val_accuracy: 0.5104 - val_loss: 1.3858\n",
      "Epoch 17/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 5s/step - accuracy: 0.5543 - loss: 1.2624 - val_accuracy: 0.5042 - val_loss: 1.3690\n",
      "Epoch 18/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 5s/step - accuracy: 0.5339 - loss: 1.3026 - val_accuracy: 0.4833 - val_loss: 1.4313\n",
      "Epoch 19/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 5s/step - accuracy: 0.5552 - loss: 1.2792 - val_accuracy: 0.4917 - val_loss: 1.3792\n",
      "Epoch 20/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - accuracy: 0.4531 - loss: 1.4326 - val_accuracy: 0.5588 - val_loss: 1.2693\n",
      "Epoch 21/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 5s/step - accuracy: 0.5712 - loss: 1.2115 - val_accuracy: 0.4969 - val_loss: 1.3734\n",
      "Epoch 22/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 5s/step - accuracy: 0.5709 - loss: 1.2375 - val_accuracy: 0.5208 - val_loss: 1.3396\n",
      "Epoch 23/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 5s/step - accuracy: 0.5499 - loss: 1.2560 - val_accuracy: 0.5281 - val_loss: 1.3354\n",
      "Epoch 24/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 5s/step - accuracy: 0.5735 - loss: 1.2038 - val_accuracy: 0.5271 - val_loss: 1.2997\n",
      "Epoch 25/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 114ms/step - accuracy: 0.5000 - loss: 1.3588 - val_accuracy: 0.4926 - val_loss: 1.3580\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_set.n // 256\n",
    "validation_steps = validation_set.n // 256\n",
    "\n",
    "resnetv2.compile(optimizer = 'adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "batch_size = 40\n",
    "history = resnetv2.fit(x=training_set,\n",
    "                    validation_data=validation_set,\n",
    "                    epochs=25,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 6s/step - accuracy: 0.5638 - loss: 1.2017 - val_accuracy: 0.5156 - val_loss: 1.3554\n",
      "Epoch 2/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 6s/step - accuracy: 0.5964 - loss: 1.1719 - val_accuracy: 0.5333 - val_loss: 1.3199\n",
      "Epoch 3/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 6s/step - accuracy: 0.5723 - loss: 1.1980 - val_accuracy: 0.5531 - val_loss: 1.2946\n",
      "Epoch 4/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 6s/step - accuracy: 0.6024 - loss: 1.1436 - val_accuracy: 0.5490 - val_loss: 1.2805\n",
      "Epoch 5/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 152ms/step - accuracy: 0.5000 - loss: 1.2136 - val_accuracy: 0.5221 - val_loss: 1.2886\n",
      "Epoch 6/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 5s/step - accuracy: 0.5904 - loss: 1.1612 - val_accuracy: 0.5229 - val_loss: 1.3015\n",
      "Epoch 7/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 5s/step - accuracy: 0.6017 - loss: 1.1273 - val_accuracy: 0.5219 - val_loss: 1.2782\n",
      "Epoch 8/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 5s/step - accuracy: 0.6012 - loss: 1.1286 - val_accuracy: 0.5521 - val_loss: 1.2566\n",
      "Epoch 9/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 5s/step - accuracy: 0.6007 - loss: 1.1358 - val_accuracy: 0.5271 - val_loss: 1.3140\n",
      "Epoch 10/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 114ms/step - accuracy: 0.6562 - loss: 1.0392 - val_accuracy: 0.6176 - val_loss: 1.1234\n",
      "Epoch 11/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 5s/step - accuracy: 0.6209 - loss: 1.0904 - val_accuracy: 0.5208 - val_loss: 1.3161\n",
      "Epoch 12/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 5s/step - accuracy: 0.6133 - loss: 1.1001 - val_accuracy: 0.5479 - val_loss: 1.2801\n",
      "Epoch 13/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 5s/step - accuracy: 0.6184 - loss: 1.0892 - val_accuracy: 0.5135 - val_loss: 1.3342\n",
      "Epoch 14/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 5s/step - accuracy: 0.6118 - loss: 1.1286 - val_accuracy: 0.5135 - val_loss: 1.3256\n",
      "Epoch 15/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 116ms/step - accuracy: 0.6562 - loss: 1.0717 - val_accuracy: 0.6250 - val_loss: 1.1966\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_set.n // 256\n",
    "validation_steps = validation_set.n // 256\n",
    "\n",
    "resnetv2.compile(optimizer = 'adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "batch_size = 40\n",
    "history = resnetv2.fit(x=training_set,\n",
    "                    validation_data=validation_set,\n",
    "                    epochs=15,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 7s/step - accuracy: 0.6567 - loss: 1.0394 - val_accuracy: 0.5323 - val_loss: 1.2811\n",
      "Epoch 2/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 6s/step - accuracy: 0.6352 - loss: 1.0490 - val_accuracy: 0.5562 - val_loss: 1.2689\n",
      "Epoch 3/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m398s\u001b[0m 6s/step - accuracy: 0.6376 - loss: 1.0393 - val_accuracy: 0.5292 - val_loss: 1.3115\n",
      "Epoch 4/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 6s/step - accuracy: 0.6282 - loss: 1.0447 - val_accuracy: 0.5229 - val_loss: 1.2800\n",
      "Epoch 5/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 148ms/step - accuracy: 0.7031 - loss: 0.9027 - val_accuracy: 0.5147 - val_loss: 1.3547\n",
      "Epoch 6/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 6s/step - accuracy: 0.6502 - loss: 1.0329 - val_accuracy: 0.5354 - val_loss: 1.2698\n",
      "Epoch 7/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 6s/step - accuracy: 0.6745 - loss: 0.9756 - val_accuracy: 0.5271 - val_loss: 1.2989\n",
      "Epoch 8/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 6s/step - accuracy: 0.6641 - loss: 0.9851 - val_accuracy: 0.5490 - val_loss: 1.3089\n",
      "Epoch 9/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 6s/step - accuracy: 0.6711 - loss: 0.9844 - val_accuracy: 0.5500 - val_loss: 1.2710\n",
      "Epoch 10/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 143ms/step - accuracy: 0.7188 - loss: 0.8889 - val_accuracy: 0.5809 - val_loss: 1.1714\n",
      "Epoch 11/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 6s/step - accuracy: 0.6646 - loss: 0.9780 - val_accuracy: 0.5458 - val_loss: 1.2703\n",
      "Epoch 12/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 6s/step - accuracy: 0.6781 - loss: 0.9407 - val_accuracy: 0.5521 - val_loss: 1.2656\n",
      "Epoch 13/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 5s/step - accuracy: 0.6867 - loss: 0.9502 - val_accuracy: 0.5656 - val_loss: 1.2651\n",
      "Epoch 14/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 5s/step - accuracy: 0.6885 - loss: 0.9358 - val_accuracy: 0.5354 - val_loss: 1.2904\n",
      "Epoch 15/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 137ms/step - accuracy: 0.7812 - loss: 0.7015 - val_accuracy: 0.5956 - val_loss: 1.1451\n",
      "Epoch 16/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 5s/step - accuracy: 0.6775 - loss: 0.9670 - val_accuracy: 0.5469 - val_loss: 1.2679\n",
      "Epoch 17/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 5s/step - accuracy: 0.7069 - loss: 0.9120 - val_accuracy: 0.5479 - val_loss: 1.2987\n",
      "Epoch 18/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 5s/step - accuracy: 0.7041 - loss: 0.8857 - val_accuracy: 0.5510 - val_loss: 1.2921\n",
      "Epoch 19/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 5s/step - accuracy: 0.7154 - loss: 0.8758 - val_accuracy: 0.5292 - val_loss: 1.3543\n",
      "Epoch 20/20\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 131ms/step - accuracy: 0.7500 - loss: 0.7501 - val_accuracy: 0.4926 - val_loss: 1.5932\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_set.n // 256\n",
    "validation_steps = validation_set.n // 256\n",
    "\n",
    "resnetv2.compile(optimizer = 'adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "batch_size = 40\n",
    "history = resnetv2.fit(x=training_set,\n",
    "                    validation_data=validation_set,\n",
    "                    epochs=20,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 6s/step - accuracy: 0.7078 - loss: 0.8884 - val_accuracy: 0.5677 - val_loss: 1.2555\n",
      "Epoch 2/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 6s/step - accuracy: 0.7035 - loss: 0.8841 - val_accuracy: 0.5323 - val_loss: 1.3247\n",
      "Epoch 3/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 6s/step - accuracy: 0.7088 - loss: 0.8660 - val_accuracy: 0.5542 - val_loss: 1.2798\n",
      "Epoch 4/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 6s/step - accuracy: 0.7205 - loss: 0.8647 - val_accuracy: 0.5906 - val_loss: 1.1759\n",
      "Epoch 5/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 140ms/step - accuracy: 0.7188 - loss: 0.8046 - val_accuracy: 0.5735 - val_loss: 1.2425\n",
      "Epoch 6/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 6s/step - accuracy: 0.7281 - loss: 0.8137 - val_accuracy: 0.5490 - val_loss: 1.3144\n",
      "Epoch 7/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 6s/step - accuracy: 0.7248 - loss: 0.8574 - val_accuracy: 0.5448 - val_loss: 1.3274\n",
      "Epoch 8/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 6s/step - accuracy: 0.7424 - loss: 0.7925 - val_accuracy: 0.5604 - val_loss: 1.3261\n",
      "Epoch 9/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 6s/step - accuracy: 0.7499 - loss: 0.7938 - val_accuracy: 0.5781 - val_loss: 1.2225\n",
      "Epoch 10/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 135ms/step - accuracy: 0.7031 - loss: 0.8205 - val_accuracy: 0.5221 - val_loss: 1.3194\n",
      "Epoch 11/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 6s/step - accuracy: 0.7363 - loss: 0.8093 - val_accuracy: 0.5615 - val_loss: 1.3060\n",
      "Epoch 12/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 6s/step - accuracy: 0.7414 - loss: 0.7829 - val_accuracy: 0.5562 - val_loss: 1.3104\n",
      "Epoch 13/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 6s/step - accuracy: 0.7433 - loss: 0.7913 - val_accuracy: 0.5531 - val_loss: 1.2677\n",
      "Epoch 14/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 6s/step - accuracy: 0.7440 - loss: 0.7803 - val_accuracy: 0.5458 - val_loss: 1.3533\n",
      "Epoch 15/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 135ms/step - accuracy: 0.7188 - loss: 0.9797 - val_accuracy: 0.5662 - val_loss: 1.2666\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_set.n // 256\n",
    "validation_steps = validation_set.n // 256\n",
    "\n",
    "resnetv2.compile(optimizer = 'adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "batch_size = 40\n",
    "history = resnetv2.fit(x=training_set,\n",
    "                    validation_data=validation_set,\n",
    "                    epochs=15,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 6s/step - accuracy: 0.7560 - loss: 0.7567 - val_accuracy: 0.5615 - val_loss: 1.3048\n",
      "Epoch 2/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 6s/step - accuracy: 0.7357 - loss: 0.7954 - val_accuracy: 0.5729 - val_loss: 1.2790\n",
      "Epoch 3/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 6s/step - accuracy: 0.7567 - loss: 0.7619 - val_accuracy: 0.5604 - val_loss: 1.3592\n",
      "Epoch 4/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 6s/step - accuracy: 0.7587 - loss: 0.7454 - val_accuracy: 0.5698 - val_loss: 1.2730\n",
      "Epoch 5/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 132ms/step - accuracy: 0.7656 - loss: 0.7419 - val_accuracy: 0.4853 - val_loss: 1.4959\n",
      "Epoch 6/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 6s/step - accuracy: 0.7647 - loss: 0.7257 - val_accuracy: 0.5677 - val_loss: 1.3024\n",
      "Epoch 7/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 6s/step - accuracy: 0.7577 - loss: 0.7593 - val_accuracy: 0.5531 - val_loss: 1.3067\n",
      "Epoch 8/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 6s/step - accuracy: 0.7690 - loss: 0.7380 - val_accuracy: 0.5667 - val_loss: 1.2920\n",
      "Epoch 9/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 6s/step - accuracy: 0.7854 - loss: 0.6889 - val_accuracy: 0.5573 - val_loss: 1.4186\n",
      "Epoch 10/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 129ms/step - accuracy: 0.7656 - loss: 0.7237 - val_accuracy: 0.5809 - val_loss: 1.4442\n",
      "Epoch 11/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 6s/step - accuracy: 0.7729 - loss: 0.7252 - val_accuracy: 0.5844 - val_loss: 1.3216\n",
      "Epoch 12/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 6s/step - accuracy: 0.7789 - loss: 0.6919 - val_accuracy: 0.5615 - val_loss: 1.3697\n",
      "Epoch 13/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 6s/step - accuracy: 0.7687 - loss: 0.7073 - val_accuracy: 0.5750 - val_loss: 1.2853\n",
      "Epoch 14/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 6s/step - accuracy: 0.7859 - loss: 0.6778 - val_accuracy: 0.5375 - val_loss: 1.4023\n",
      "Epoch 15/15\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 149ms/step - accuracy: 0.7812 - loss: 0.7361 - val_accuracy: 0.5294 - val_loss: 1.5182\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_set.n // 256\n",
    "validation_steps = validation_set.n // 256\n",
    "\n",
    "resnetv2.compile(optimizer = 'adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "batch_size = 40\n",
    "history = resnetv2.fit(x=training_set,\n",
    "                    validation_data=validation_set,\n",
    "                    epochs=15,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnetv2.save(\"resnetv2-krg-1.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 5s/step - accuracy: 0.7838 - loss: 0.6884 - val_accuracy: 0.5500 - val_loss: 1.3498\n",
      "Epoch 2/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 5s/step - accuracy: 0.7875 - loss: 0.6907 - val_accuracy: 0.5250 - val_loss: 1.4720\n",
      "Epoch 3/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 5s/step - accuracy: 0.7886 - loss: 0.6924 - val_accuracy: 0.5792 - val_loss: 1.3355\n",
      "Epoch 4/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 5s/step - accuracy: 0.7885 - loss: 0.6732 - val_accuracy: 0.5729 - val_loss: 1.3568\n",
      "Epoch 5/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 126ms/step - accuracy: 0.7812 - loss: 0.6745 - val_accuracy: 0.5662 - val_loss: 1.3609\n",
      "Epoch 6/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 5s/step - accuracy: 0.8139 - loss: 0.6050 - val_accuracy: 0.5500 - val_loss: 1.3809\n",
      "Epoch 7/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 5s/step - accuracy: 0.8086 - loss: 0.6143 - val_accuracy: 0.5469 - val_loss: 1.3840\n",
      "Epoch 8/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 5s/step - accuracy: 0.8046 - loss: 0.6244 - val_accuracy: 0.5469 - val_loss: 1.3457\n",
      "Epoch 9/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 5s/step - accuracy: 0.8210 - loss: 0.6148 - val_accuracy: 0.5479 - val_loss: 1.3996\n",
      "Epoch 10/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 125ms/step - accuracy: 0.8906 - loss: 0.4449 - val_accuracy: 0.4338 - val_loss: 1.7674\n",
      "Epoch 11/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 5s/step - accuracy: 0.8141 - loss: 0.6297 - val_accuracy: 0.5594 - val_loss: 1.3852\n",
      "Epoch 12/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 5s/step - accuracy: 0.8271 - loss: 0.5857 - val_accuracy: 0.5698 - val_loss: 1.3672\n",
      "Epoch 13/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 5s/step - accuracy: 0.8147 - loss: 0.6141 - val_accuracy: 0.5698 - val_loss: 1.4724\n",
      "Epoch 14/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 5s/step - accuracy: 0.8298 - loss: 0.5719 - val_accuracy: 0.5500 - val_loss: 1.4073\n",
      "Epoch 15/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - accuracy: 0.7969 - loss: 0.6716 - val_accuracy: 0.5294 - val_loss: 1.4705\n",
      "Epoch 16/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 5s/step - accuracy: 0.8211 - loss: 0.5996 - val_accuracy: 0.5615 - val_loss: 1.3672\n",
      "Epoch 17/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 5s/step - accuracy: 0.8172 - loss: 0.5855 - val_accuracy: 0.5448 - val_loss: 1.4425\n",
      "Epoch 18/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 5s/step - accuracy: 0.8434 - loss: 0.5346 - val_accuracy: 0.5521 - val_loss: 1.4217\n",
      "Epoch 19/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 5s/step - accuracy: 0.8458 - loss: 0.5309 - val_accuracy: 0.5573 - val_loss: 1.5046\n",
      "Epoch 20/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 116ms/step - accuracy: 0.8750 - loss: 0.5365 - val_accuracy: 0.5515 - val_loss: 1.4721\n",
      "Epoch 21/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 5s/step - accuracy: 0.8393 - loss: 0.5511 - val_accuracy: 0.5802 - val_loss: 1.3200\n",
      "Epoch 22/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 5s/step - accuracy: 0.8268 - loss: 0.5799 - val_accuracy: 0.5302 - val_loss: 1.4434\n",
      "Epoch 23/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 5s/step - accuracy: 0.8406 - loss: 0.5443 - val_accuracy: 0.5625 - val_loss: 1.3593\n",
      "Epoch 24/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 5s/step - accuracy: 0.8412 - loss: 0.5306 - val_accuracy: 0.5000 - val_loss: 1.6041\n",
      "Epoch 25/25\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 116ms/step - accuracy: 0.7969 - loss: 0.7124 - val_accuracy: 0.5147 - val_loss: 1.5123\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_set.n // 256\n",
    "validation_steps = validation_set.n // 256\n",
    "\n",
    "resnetv2.compile(optimizer = 'adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "batch_size = 40\n",
    "history = resnetv2.fit(x=training_set,\n",
    "                    validation_data=validation_set,\n",
    "                    epochs=25,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 6s/step - accuracy: 0.8654 - loss: 0.4625 - val_accuracy: 0.5542 - val_loss: 1.5622\n",
      "Epoch 2/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 5s/step - accuracy: 0.8833 - loss: 0.4260 - val_accuracy: 0.5698 - val_loss: 1.4389\n",
      "Epoch 3/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 5s/step - accuracy: 0.8795 - loss: 0.4237 - val_accuracy: 0.5635 - val_loss: 1.4712\n",
      "Epoch 4/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 5s/step - accuracy: 0.8691 - loss: 0.4493 - val_accuracy: 0.5615 - val_loss: 1.5015\n",
      "Epoch 5/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 134ms/step - accuracy: 0.8906 - loss: 0.4342 - val_accuracy: 0.5515 - val_loss: 1.5021\n",
      "Epoch 6/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 5s/step - accuracy: 0.8759 - loss: 0.4409 - val_accuracy: 0.5406 - val_loss: 1.4903\n",
      "Epoch 7/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 5s/step - accuracy: 0.8883 - loss: 0.3980 - val_accuracy: 0.5760 - val_loss: 1.3980\n",
      "Epoch 8/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 5s/step - accuracy: 0.9004 - loss: 0.3715 - val_accuracy: 0.5437 - val_loss: 1.5866\n",
      "Epoch 9/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 5s/step - accuracy: 0.8835 - loss: 0.4252 - val_accuracy: 0.5875 - val_loss: 1.4938\n",
      "Epoch 10/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 131ms/step - accuracy: 0.8750 - loss: 0.4476 - val_accuracy: 0.5735 - val_loss: 1.4402\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_set.n // 256\n",
    "validation_steps = validation_set.n // 256\n",
    "\n",
    "resnetv2.compile(optimizer = 'adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "batch_size = 40\n",
    "history = resnetv2.fit(x=training_set,\n",
    "                    validation_data=validation_set,\n",
    "                    epochs=10,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnetv2.save(\"resnetv2-krgg-170.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_resnetv2_krg = tf.keras.models.load_model(\"resnetv2-krg-1.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 6s/step - accuracy: 0.7868 - loss: 0.6917 - val_accuracy: 0.6000 - val_loss: 1.2589\n",
      "Epoch 2/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 6s/step - accuracy: 0.7894 - loss: 0.6757 - val_accuracy: 0.5594 - val_loss: 1.3294\n",
      "Epoch 3/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 6s/step - accuracy: 0.8008 - loss: 0.6506 - val_accuracy: 0.5573 - val_loss: 1.3606\n",
      "Epoch 4/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 6s/step - accuracy: 0.8028 - loss: 0.6528 - val_accuracy: 0.5615 - val_loss: 1.3501\n",
      "Epoch 5/10\n",
      "\u001b[1m 1/62\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:14\u001b[0m 5s/step - accuracy: 0.8125 - loss: 0.6064"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 157ms/step - accuracy: 0.8125 - loss: 0.6064 - val_accuracy: 0.5588 - val_loss: 1.3411\n",
      "Epoch 6/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 6s/step - accuracy: 0.7998 - loss: 0.6379 - val_accuracy: 0.5656 - val_loss: 1.3176\n",
      "Epoch 7/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 6s/step - accuracy: 0.8150 - loss: 0.6077 - val_accuracy: 0.5490 - val_loss: 1.4277\n",
      "Epoch 8/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 5s/step - accuracy: 0.8071 - loss: 0.6473 - val_accuracy: 0.5531 - val_loss: 1.3549\n",
      "Epoch 9/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 5s/step - accuracy: 0.8153 - loss: 0.6132 - val_accuracy: 0.5531 - val_loss: 1.3818\n",
      "Epoch 10/10\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 136ms/step - accuracy: 0.7812 - loss: 0.8092 - val_accuracy: 0.6250 - val_loss: 1.2019\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_set.n // 256\n",
    "validation_steps = validation_set.n // 256\n",
    "\n",
    "new_resnetv2_krg.compile(optimizer = 'adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "batch_size = 40\n",
    "history = new_resnetv2_krg.fit(x=training_set,\n",
    "                    validation_data=validation_set,\n",
    "                    epochs=10,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 6s/step - accuracy: 0.7969 - loss: 0.6333 - val_accuracy: 0.5437 - val_loss: 1.4199\n",
      "Epoch 2/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 6s/step - accuracy: 0.8232 - loss: 0.5902 - val_accuracy: 0.5604 - val_loss: 1.3631\n",
      "Epoch 3/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 6s/step - accuracy: 0.8259 - loss: 0.5748 - val_accuracy: 0.5719 - val_loss: 1.3338\n",
      "Epoch 4/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 6s/step - accuracy: 0.8282 - loss: 0.5743 - val_accuracy: 0.5521 - val_loss: 1.4228\n",
      "Epoch 5/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 130ms/step - accuracy: 0.7656 - loss: 0.7020 - val_accuracy: 0.6397 - val_loss: 1.1352\n",
      "Epoch 6/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 6s/step - accuracy: 0.8366 - loss: 0.5643 - val_accuracy: 0.5490 - val_loss: 1.3635\n",
      "Epoch 7/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 6s/step - accuracy: 0.8387 - loss: 0.5552 - val_accuracy: 0.5594 - val_loss: 1.4107\n",
      "Epoch 8/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 6s/step - accuracy: 0.8257 - loss: 0.5788 - val_accuracy: 0.5510 - val_loss: 1.4116\n",
      "Epoch 9/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 6s/step - accuracy: 0.8280 - loss: 0.5742 - val_accuracy: 0.5656 - val_loss: 1.3577\n",
      "Epoch 10/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 138ms/step - accuracy: 0.7500 - loss: 0.6914 - val_accuracy: 0.5515 - val_loss: 1.3650\n",
      "Epoch 11/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 6s/step - accuracy: 0.8429 - loss: 0.5431 - val_accuracy: 0.5573 - val_loss: 1.4206\n",
      "Epoch 12/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 6s/step - accuracy: 0.8257 - loss: 0.5477 - val_accuracy: 0.5458 - val_loss: 1.4308\n",
      "Epoch 13/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 5s/step - accuracy: 0.8385 - loss: 0.5642 - val_accuracy: 0.5552 - val_loss: 1.4183\n",
      "Epoch 14/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 5s/step - accuracy: 0.8358 - loss: 0.5551 - val_accuracy: 0.5542 - val_loss: 1.3656\n",
      "Epoch 15/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 134ms/step - accuracy: 0.9062 - loss: 0.5510 - val_accuracy: 0.6250 - val_loss: 1.2980\n",
      "Epoch 16/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 6s/step - accuracy: 0.8351 - loss: 0.5569 - val_accuracy: 0.5635 - val_loss: 1.4438\n",
      "Epoch 17/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 5s/step - accuracy: 0.8356 - loss: 0.5461 - val_accuracy: 0.5646 - val_loss: 1.3747\n",
      "Epoch 18/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 6s/step - accuracy: 0.8484 - loss: 0.5316 - val_accuracy: 0.5521 - val_loss: 1.4287\n",
      "Epoch 19/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 5s/step - accuracy: 0.8507 - loss: 0.5053 - val_accuracy: 0.5781 - val_loss: 1.3919\n",
      "Epoch 20/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 131ms/step - accuracy: 0.7656 - loss: 0.6565 - val_accuracy: 0.5515 - val_loss: 1.5281\n",
      "Epoch 21/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 5s/step - accuracy: 0.8520 - loss: 0.5248 - val_accuracy: 0.5604 - val_loss: 1.4192\n",
      "Epoch 22/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 5s/step - accuracy: 0.8401 - loss: 0.5339 - val_accuracy: 0.5729 - val_loss: 1.4300\n",
      "Epoch 23/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 5s/step - accuracy: 0.8588 - loss: 0.4842 - val_accuracy: 0.5813 - val_loss: 1.3835\n",
      "Epoch 24/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 6s/step - accuracy: 0.8725 - loss: 0.4683 - val_accuracy: 0.5625 - val_loss: 1.4164\n",
      "Epoch 25/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 130ms/step - accuracy: 0.8750 - loss: 0.4446 - val_accuracy: 0.4853 - val_loss: 1.5661\n",
      "Epoch 26/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 5s/step - accuracy: 0.8721 - loss: 0.4600 - val_accuracy: 0.5813 - val_loss: 1.4033\n",
      "Epoch 27/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 5s/step - accuracy: 0.8689 - loss: 0.4691 - val_accuracy: 0.5677 - val_loss: 1.3936\n",
      "Epoch 28/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 5s/step - accuracy: 0.8699 - loss: 0.4704 - val_accuracy: 0.5604 - val_loss: 1.4231\n",
      "Epoch 29/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 5s/step - accuracy: 0.8582 - loss: 0.4831 - val_accuracy: 0.5823 - val_loss: 1.4118\n",
      "Epoch 30/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 131ms/step - accuracy: 0.8281 - loss: 0.5530 - val_accuracy: 0.5735 - val_loss: 1.5444\n",
      "Epoch 31/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 5s/step - accuracy: 0.8679 - loss: 0.4555 - val_accuracy: 0.5562 - val_loss: 1.4492\n",
      "Epoch 32/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 5s/step - accuracy: 0.8675 - loss: 0.4696 - val_accuracy: 0.5792 - val_loss: 1.3831\n",
      "Epoch 33/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 5s/step - accuracy: 0.8778 - loss: 0.4295 - val_accuracy: 0.5677 - val_loss: 1.4151\n",
      "Epoch 34/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 5s/step - accuracy: 0.8701 - loss: 0.4494 - val_accuracy: 0.5625 - val_loss: 1.5116\n",
      "Epoch 35/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 128ms/step - accuracy: 0.8750 - loss: 0.3868 - val_accuracy: 0.5368 - val_loss: 1.4241\n",
      "Epoch 36/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 5s/step - accuracy: 0.8724 - loss: 0.4448 - val_accuracy: 0.5573 - val_loss: 1.5578\n",
      "Epoch 37/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 5s/step - accuracy: 0.8772 - loss: 0.4371 - val_accuracy: 0.5646 - val_loss: 1.5193\n",
      "Epoch 38/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 5s/step - accuracy: 0.8756 - loss: 0.4478 - val_accuracy: 0.5688 - val_loss: 1.4445\n",
      "Epoch 39/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 5s/step - accuracy: 0.8826 - loss: 0.4188 - val_accuracy: 0.5573 - val_loss: 1.4521\n",
      "Epoch 40/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 128ms/step - accuracy: 0.8750 - loss: 0.3569 - val_accuracy: 0.5294 - val_loss: 1.4518\n",
      "Epoch 41/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 5s/step - accuracy: 0.8759 - loss: 0.4244 - val_accuracy: 0.5667 - val_loss: 1.4537\n",
      "Epoch 42/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 5s/step - accuracy: 0.8754 - loss: 0.4263 - val_accuracy: 0.5531 - val_loss: 1.4407\n",
      "Epoch 43/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 5s/step - accuracy: 0.8841 - loss: 0.4100 - val_accuracy: 0.5510 - val_loss: 1.5048\n",
      "Epoch 44/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 5s/step - accuracy: 0.8879 - loss: 0.4076 - val_accuracy: 0.5292 - val_loss: 1.5530\n",
      "Epoch 45/45\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 128ms/step - accuracy: 0.9062 - loss: 0.3852 - val_accuracy: 0.5882 - val_loss: 1.5158\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_set.n // 256\n",
    "validation_steps = validation_set.n // 256\n",
    "\n",
    "new_resnetv2_krg.compile(optimizer = 'adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "batch_size = 40\n",
    "history = new_resnetv2_krg.fit(x=training_set,\n",
    "                    validation_data=validation_set,\n",
    "                    epochs=45,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_resnetv2_krg.save(\"resnetv2-krg-170.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG19Train_dikit_new = tf.keras.models.load_model(\"C:/Users/ACER/Downloads/VGG19Augmented_TrainableDikit6/VGG19Augmented_TrainableDikit6.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2820s\u001b[0m 23s/step - accuracy: 0.7137 - loss: 0.7779\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_set.n // 128\n",
    "validation_steps = validation_set.n // 128\n",
    "\n",
    "VGG19Train_dikit_new.compile(optimizer = 'adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "batch_size = 40\n",
    "history = VGG19Train_dikit_new.fit(x=training_set,\n",
    "                    epochs=1,\n",
    "                    steps_per_epoch=steps_per_epoch\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3081s\u001b[0m 25s/step - accuracy: 0.7030 - loss: 0.8059\n",
      "Epoch 2/4\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4417s\u001b[0m 36s/step - accuracy: 0.7172 - loss: 0.7685\n",
      "Epoch 3/4\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.6719 - loss: 0.7991    \n",
      "Epoch 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4091s\u001b[0m 33s/step - accuracy: 0.7297 - loss: 0.7301\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_set.n // 128\n",
    "validation_steps = validation_set.n // 128\n",
    "\n",
    "VGG19Train_dikit_new.compile(optimizer = 'adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "batch_size = 40\n",
    "history = VGG19Train_dikit_new.fit(x=training_set,\n",
    "                    epochs=4,\n",
    "                    steps_per_epoch=steps_per_epoch\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2924s\u001b[0m 23s/step - accuracy: 0.7294 - loss: 0.7361\n",
      "Epoch 2/5\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2884s\u001b[0m 23s/step - accuracy: 0.7386 - loss: 0.7207\n",
      "Epoch 3/5\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - accuracy: 0.7255 - loss: 1.0132  \n",
      "Epoch 4/5\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3006s\u001b[0m 24s/step - accuracy: 0.7544 - loss: 0.6850\n",
      "Epoch 5/5\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2872s\u001b[0m 23s/step - accuracy: 0.7513 - loss: 0.6693\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_set.n // 128\n",
    "validation_steps = validation_set.n // 128\n",
    "\n",
    "VGG19Train_dikit_new.compile(optimizer = 'adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "batch_size = 40\n",
    "history = VGG19Train_dikit_new.fit(x=training_set,\n",
    "                    epochs=5,\n",
    "                    steps_per_epoch=steps_per_epoch\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2731s\u001b[0m 22s/step - accuracy: 0.7322 - loss: 0.7248\n",
      "Epoch 2/17\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2873s\u001b[0m 23s/step - accuracy: 0.7399 - loss: 0.7126\n",
      "Epoch 3/17\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.7031 - loss: 0.8141  \n",
      "Epoch 4/17\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3093s\u001b[0m 25s/step - accuracy: 0.7741 - loss: 0.6347\n",
      "Epoch 5/17\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3262s\u001b[0m 26s/step - accuracy: 0.7561 - loss: 0.6521\n",
      "Epoch 6/17\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.7344 - loss: 0.7084  \n",
      "Epoch 7/17\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2651s\u001b[0m 21s/step - accuracy: 0.7856 - loss: 0.5953\n",
      "Epoch 8/17\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2719s\u001b[0m 22s/step - accuracy: 0.7714 - loss: 0.6355\n",
      "Epoch 9/17\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.6875 - loss: 0.7189  \n",
      "Epoch 10/17\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2809s\u001b[0m 23s/step - accuracy: 0.7963 - loss: 0.5772\n",
      "Epoch 11/17\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2724s\u001b[0m 22s/step - accuracy: 0.7795 - loss: 0.5939\n",
      "Epoch 12/17\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.7031 - loss: 0.7196  \n",
      "Epoch 13/17\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2672s\u001b[0m 22s/step - accuracy: 0.8003 - loss: 0.5745\n",
      "Epoch 14/17\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2830s\u001b[0m 23s/step - accuracy: 0.7875 - loss: 0.5813\n",
      "Epoch 15/17\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - accuracy: 0.8125 - loss: 0.5636  \n",
      "Epoch 16/17\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2855s\u001b[0m 23s/step - accuracy: 0.8044 - loss: 0.5569\n",
      "Epoch 17/17\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2726s\u001b[0m 22s/step - accuracy: 0.7999 - loss: 0.5749\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = training_set.n // 128\n",
    "validation_steps = validation_set.n // 128\n",
    "\n",
    "VGG19Train_dikit_new.compile(optimizer = 'adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "batch_size = 40\n",
    "history = VGG19Train_dikit_new.fit(x=training_set,\n",
    "                    epochs=17,\n",
    "                    steps_per_epoch=steps_per_epoch\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG19Train_dikit_new.save(\"VGG19_TrainableDikit_87.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
